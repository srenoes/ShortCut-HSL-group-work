{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Data analysis file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is the main data analysis file which does all the analysis task, answers all questions \n",
    "and is so to say the major part of the report.\n",
    "The major self set task during the data analysis was to make sense of the counted cyclist data and try to evaluate traffic \n",
    "not so much as a function of time, but moreover with spatial revolution.\n",
    "This is somewaht difficult since directional traffic information is not supplied, but one can only make sense of the data by trying to reconstruct the underlying traffic\n",
    "\n",
    "I used two methods: 1)Visualise traffic on a map and by that gain some insight 2)try to mathematically attack the problem by other means\n",
    "\n",
    "This is interesting as you would want to know more informatin than just numbers from such big datasets, yet this is not a simple task\n",
    "\n",
    "### Use of the files\n",
    "\n",
    "Some of the files are so big that it was nesesairy to generate them after download. Github is a major headake with files bigger than 50Mbyte. Running the code in All_Bikers.ipynb is not necesairy though open_street_ map_ data_aquisition.ipynb must be executed prior to running this file. This can be unfortunately quite tideous \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load pretreated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers=pd.read_csv('All_bikers.csv')\n",
    "ALL_Bikers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data again to datetime as it does not stay like that\n",
    "Second plot how much data is available when from Helsinki Espoo and Vanta\n",
    "Finally make some indices to have easier access to the respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers=pd.read_csv('All_bikers.csv')\n",
    "ALL_Bikers=ALL_Bikers.reset_index()\n",
    "ALL_Bikers['Date']=pd.to_datetime(ALL_Bikers['Date'])\n",
    "ALL_Bikers=ALL_Bikers.set_index('Date')\n",
    "ALL_Bikers=ALL_Bikers.iloc[:,1:]\n",
    "\n",
    "ax=ALL_Bikers.plot(y=\"nData\", figsize=[20,10])\n",
    "ALL_Bikers.plot(ax=ax,y='nData_HEL')\n",
    "ALL_Bikers.plot(ax=ax,y='nData_ESP')\n",
    "ALL_Bikers.plot(ax=ax,y='nData_VAN')\n",
    "\n",
    "plt.show()\n",
    "cIndex_Vantaa=pd.Index(['Asolanvayla P', 'Asolanvayla E', 'Hakunilantie P',\n",
    "       'Hakunilantie E', 'Kyytitie I', 'Kyytitie L', 'Kaislaranta P',\n",
    "       'Kaislaranta E', 'Kuusijarvi P', 'Kuusijarvi E', 'Kytopuisto P',\n",
    "       'Kytöpuisto E', 'Pellas I', 'Pellas L', 'Simonkylantie P',\n",
    "       'Simonkylantie E', 'Solkikuja I', 'Solkikuja L', 'Vanha Porvoontie P',\n",
    "       'Vanha Porvoontie E', 'Vantaanlaaksontie P', 'Vantaanlaaksontie E',\n",
    "       'Ylastontie I', 'Ylastontie L'],\n",
    "      dtype='object')\n",
    "cIndex_Espoo=pd.Index(['Espoon portti (Eco-Counter)', 'Espoonlahdenraitti (Eco-Counter)',\n",
    "       'Gallen-Kallela (Eco-Counter)', 'Gallen-Kallelan tie (DSL10)',\n",
    "       'Haukilahti (Viacount)', 'Kalevalantien alikulku (DSL10)',\n",
    "       'Keha I, Laajalahti (DSL10)', 'Keha I, Laajalahti (Eco-counter)',\n",
    "       'Keilaniemi, Keilaterassi (Viacount)',\n",
    "       'Keskuspuisto, etelahaara, ita (Viacount 2)',\n",
    "       'Keskuspuisto, etelahaara, lansi (Viacount 2)',\n",
    "       'Keskuspuisto, Grimangen (Viacount 2)',\n",
    "       'Keskuspuisto, Mossenkar (Viacount 2)', 'Kiltapolku (Viacount 2)',\n",
    "       'Kiltaraitti, etela (Viacount 2)',\n",
    "       'Kiltaraitti, pohjoinen (Viacount 2)', 'Kirkkojarventie (DSL10)',\n",
    "       'Kivenlahden uimaranta (Viacount)', 'Kivenlahti (Viacount)',\n",
    "       'Lansivayla (Eco-counter)', 'Lansivayla, Karhusaari (DSL10)',\n",
    "       'Martinsillantie (DSL10)', 'Merituulentie (DSL10)',\n",
    "       'Olarinkatu (Eco-Counter)', 'Otaniemi, Otaranta (Viacount)',\n",
    "       'Pitkajarventie (DSL10)', 'Pohjantien ylikulku (DSL10)',\n",
    "       'Pohjantien ylikulku (Eco-Counter)', 'Pohjantien ylikulku (Viacount 2)',\n",
    "       'Paivankestamonpolku, Kera (Eco-Counter)',\n",
    "       'Rantaradanraitti, Helsingin raja (Viacount 2)', 'Soukka (Viacount)',\n",
    "       'Suomenlahdentie (Eco-Counter)',\n",
    "       'Suomenlahdentie, etelainen (viacount)',\n",
    "       'Suomenlahdentie, pohjoinen (Viacount)',\n",
    "       'Tapiola,Lansituulenkuja (Eco-Counter)',\n",
    "       'Turuntie, Rantaradanreitti (Eco-Counter)',\n",
    "       'Vihdintie, Kalajarven itapuoli (Viacount 2)',\n",
    "       'Vihdintie, Uusmaki (DSL10)', 'Ylismaentie,Suurpelto (Eco-Counter)'],\n",
    "      dtype='object')\n",
    "cIndex_Helsinki=pd.Index(['Auroransilta', 'Etelaesplanadi', 'Huopalahti (station)',\n",
    "       'Kaisaniemi/Elaintarhanlahti', 'Kaivokatu', 'Kulosaari bridge south',\n",
    "       'Kulosaaren silta po. ', 'Kuusisaarentie', 'Kapyla, Pohjoisbaana',\n",
    "       'Lauttasaarin bridge south side', 'Merikannontie',\n",
    "       'Munkkiniemi bridge south side', 'Munkkiniemi bridge north side',\n",
    "       'Heperia park/Ooppera', 'Pitkasilta itapuoli', 'Pitkasilta west side',\n",
    "       'Lauttasaari bridge north side', 'Ratapihantie', 'Viikintie', 'Baana'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set\n",
    "\n",
    "The data is not complete (see figures above and below) but moreover especially for vantaa and espoo there is a lot of voids in the data represented by Nones. This is tricky since especially the mathematical models cannot deal with such voids.\n",
    "Notheless grouping can also be successfully applied here as we will see for the first task\n",
    "\n",
    "Yet for the second task we will probably use the data of mid 2018 - end 2019 where there is least voids\n",
    "\n",
    "Another very difficult aspect was the incompleteness of the positional data, respective the positions separately provides were in a weird coordinate system which is used inside Finland for mapping. Thus combining positional data with time series data was a bit tideous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers.loc[ALL_Bikers.nData>=30].plot(y='nData',marker='o',linestyle='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Preprosessing was separately done in 2 extra files. One dealt with the extra treatment of the data supplied by Kata to include own needed properties (ALL_Bikers) and the other one deals with some preprosessing related to gathering data from open streetmap. Used libraries apart from standard and minor ones are Pandas, GeoPandas, osmnx, networkx, scipy, (numpy)\n",
    "and sklearn for PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main plotting function plus explanation snapshots for powerpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from geopandas import GeoSeries\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib as mpl\n",
    "from scipy.spatial import Delaunay, delaunay_plot_2d\n",
    "\n",
    "def plot_bikers(HEL_boundary,ESP_boundary,VAN_boundary,HEL_landuse,ESP_landuse,VAN_landuse,asemat,column,G_simple,title,vmin,vmax,snapshots=False,barlabel=True):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1,figsize=[20,10])\n",
    "    \n",
    "    ax2 = plt.axes([0.26, 0.6, .24, .255])\n",
    "    \n",
    "    ax.set_xlim([360000, 402500])\n",
    "    ax.set_ylim([6665000, 6697500])\n",
    "    ax2.set_xlim([377500, 390000])\n",
    "    ax2.set_ylim([6670000, 6677500])\n",
    "    ax.set_axis_off()\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    ax.set_title(title,fontdict={'fontsize':30})\n",
    "    \n",
    "    ax=HEL_boundary.plot(ax=ax,edgecolor=\"red\",zorder=4)\n",
    "    ax=ESP_boundary.plot(ax=ax,edgecolor=\"red\",zorder=5)\n",
    "    ax=VAN_boundary.plot(ax=ax,edgecolor=\"red\",zorder=6)\n",
    "    ax2=HEL_boundary.plot(ax=ax2,edgecolor=\"red\",zorder=4)\n",
    "    ax2=ESP_boundary.plot(ax=ax2,edgecolor=\"red\",zorder=5)\n",
    "    ax2=VAN_boundary.plot(ax=ax2,edgecolor=\"red\",zorder=6)\n",
    "    \n",
    "    ax=HEL_landuse.plot(ax=ax,facecolor=\"grey\",alpha=0.8,zorder=1)\n",
    "    ax=ESP_landuse.plot(ax=ax,facecolor=\"grey\",alpha=0.8,zorder=2)\n",
    "    ax=VAN_landuse.plot(ax=ax,facecolor=\"grey\",alpha=0.8,zorder=3)\n",
    "    ax2=HEL_landuse.plot(ax=ax2,facecolor=\"grey\",alpha=0.8,zorder=1)\n",
    "    ax2=ESP_landuse.plot(ax=ax2,facecolor=\"grey\",alpha=0.8,zorder=2)\n",
    "    ax2=VAN_landuse.plot(ax=ax2,facecolor=\"grey\",alpha=0.8,zorder=3)\n",
    "\n",
    "    if snapshots: # make figures step by step and save to illustrate the procedures in plotting\n",
    "        figsnap, axsnap = plt.subplots(nrows=1,figsize=[20,10])\n",
    "        ax2snap = plt.axes([0.26, 0.6, .24, .255])\n",
    "        axsnap.set_xlim([360000, 402500])\n",
    "        axsnap.set_ylim([6665000, 6697500])\n",
    "        ax2snap.set_xlim([377500, 390000])\n",
    "        ax2snap.set_ylim([6670000, 6677500])\n",
    "        axsnap.set_axis_off()\n",
    "        ax2snap.set_xticks([])\n",
    "        ax2snap.set_yticks([])\n",
    "        axsnap.set_title(title,fontdict={'fontsize':30})\n",
    "    \n",
    "        axsnap=HEL_boundary.plot(ax=axsnap,edgecolor=\"red\",zorder=4)\n",
    "        axsnap=ESP_boundary.plot(ax=axsnap,edgecolor=\"red\",zorder=5)\n",
    "        axsnap=VAN_boundary.plot(ax=axsnap,edgecolor=\"red\",zorder=6)\n",
    "        ax2snap=HEL_boundary.plot(ax=ax2snap,edgecolor=\"red\",zorder=4)\n",
    "        ax2snap=ESP_boundary.plot(ax=ax2snap,edgecolor=\"red\",zorder=5)\n",
    "        ax2snap=VAN_boundary.plot(ax=ax2snap,edgecolor=\"red\",zorder=6)\n",
    "    \n",
    "        axsnap=HEL_landuse.plot(ax=axsnap,facecolor=\"grey\",alpha=0.8,zorder=1)\n",
    "        axsnap=ESP_landuse.plot(ax=axsnap,facecolor=\"grey\",alpha=0.8,zorder=2)\n",
    "        axsnap=VAN_landuse.plot(ax=axsnap,facecolor=\"grey\",alpha=0.8,zorder=3)\n",
    "        ax2snap=HEL_landuse.plot(ax=ax2snap,facecolor=\"grey\",alpha=0.8,zorder=1)\n",
    "        ax2snap=ESP_landuse.plot(ax=ax2snap,facecolor=\"grey\",alpha=0.8,zorder=2)\n",
    "        ax2snap=VAN_landuse.plot(ax=ax2snap,facecolor=\"grey\",alpha=0.8,zorder=3)\n",
    "        i=1\n",
    "        plt.gcf().savefig(f'./pictures/snapshot{i:02}.png', bbox_inches='tight', dpi=400);\n",
    "        # First snapshot cotaining only basic OSM stuff\n",
    "        \n",
    "        points=[]\n",
    "        for point in asemat.geometry:\n",
    "            point=point.coords[:][0]\n",
    "            points.append([point[0], point[1]])\n",
    "        points=np.array(points)\n",
    "        points=np.unique(points,axis=0)\n",
    "        tri = Delaunay(points)\n",
    "\n",
    "        figsnap = delaunay_plot_2d(tri,ax=axsnap)\n",
    "        fig2snap = delaunay_plot_2d(tri,ax=ax2snap)\n",
    "        \n",
    "        i=2\n",
    "        plt.gcf().savefig(f'./pictures/snapshot{i:02}.png', bbox_inches='tight', dpi=400);\n",
    "        # Second show the Delaunay used to find paths\n",
    "\n",
    "\n",
    "    \n",
    "    G_simple_gdf_nodes,G_simple_gdf_edges=ox.graph_to_gdfs(G_simple)\n",
    "    G_simple_gdf_edges.plot(ax=ax,linewidth=1,zorder=7,color='red')\n",
    "    G_simple_gdf_edges.plot(ax=ax2,linewidth=1,zorder=7,color='red')\n",
    "\n",
    "    ax=asemat.plot(ax=ax,markersize=40,column=column,zorder=8,vmin=vmin, vmax=vmax,norm=colors.Normalize(vmin,vmax))\n",
    "    ax2=asemat.plot(ax=ax2,markersize=40,column=column,zorder=8,vmin=vmin, vmax=vmax,norm=colors.Normalize(vmin,vmax))\n",
    "\n",
    "    if snapshots:\n",
    "        G_simple_gdf_edges.plot(ax=axsnap,linewidth=1,zorder=7,color='red')\n",
    "        G_simple_gdf_edges.plot(ax=ax2snap,linewidth=1,zorder=7,color='red')\n",
    "\n",
    "        axsnap=asemat.plot(ax=axsnap,markersize=40,column=column,zorder=8,vmin=vmin, vmax=vmax,norm=colors.Normalize(vmin,vmax))\n",
    "        ax2snap=asemat.plot(ax=ax2snap,markersize=40,column=column,zorder=8,vmin=vmin, vmax=vmax,norm=colors.Normalize(vmin,vmax))\n",
    "        i=3\n",
    "        plt.gcf().savefig(f'./pictures/snapshot{i:02}.png', bbox_inches='tight', dpi=400);\n",
    "        # Third snapshot shows the paths generated from the triangulation, finding paths with networkx\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    z=asemat[column].values\n",
    "    pos=np.array([points.coords[:][0] for points in asemat.geometry])\n",
    "    x=pos[:,0]\n",
    "    y=pos[:,1]\n",
    "    \n",
    "    #https://matplotlib.org/3.1.0/gallery/images_contours_and_fields/irregulardatagrid.html#sphx-glr-gallery-images-contours-and-fields-irregulardatagrid-py\n",
    "    #ax.tricontour(x, y, z, levels=20, linewidths=0.5, colors='k')\n",
    "    cntr1 = ax.tricontourf(x, y, z, levels=20, cmap=\"RdBu_r\",vmin=vmin, vmax=vmax,norm=colors.Normalize(vmin,vmax))\n",
    "    cbar=fig.colorbar(mpl.cm.ScalarMappable(norm=colors.Normalize(vmin,vmax),cmap=\"RdBu_r\"),ax=ax)\n",
    "    cbar.ax.tick_params(axis='y', labelsize=18)\n",
    "    if barlabel:\n",
    "        cbar.set_label(label='Bike Counts/h',fontsize=20)\n",
    "    cntr2 = ax2.tricontourf(x, y, z, levels=20, cmap=\"RdBu_r\",vmin=vmin, vmax=vmax,norm=colors.Normalize(vmin,vmax))\n",
    "    \n",
    "    if snapshots:\n",
    "        cntr1snap = axsnap.tricontourf(x, y, z, levels=20, cmap=\"RdBu_r\",vmin=vmin, vmax=vmax,norm=colors.Normalize(vmin,vmax))\n",
    "        cbarsnap=figsnap.colorbar(mpl.cm.ScalarMappable(norm=colors.Normalize(vmin,vmax),cmap=\"RdBu_r\"),ax=axsnap)\n",
    "        cbarsnap.ax.tick_params(axis='y', labelsize=18)\n",
    "        if barlabel:\n",
    "            cbarsnap.set_label(label='Bike Counts/h',fontsize=20)\n",
    "        cntr2snap = ax2snap.tricontourf(x, y, z, levels=20, cmap=\"RdBu_r\",vmin=vmin, vmax=vmax,norm=colors.Normalize(vmin,vmax))\n",
    "        i=4\n",
    "        plt.gcf().savefig(f'./pictures/snapshot{i:02}.png', bbox_inches='tight', dpi=400);\n",
    "        plt.clf();# close figure that was used only for snapshots\n",
    "        # Last snapshot showing all, including contourplot\n",
    "\n",
    "    \n",
    "    return fig,ax,ax2\n",
    "\n",
    "\n",
    "\n",
    "city1 = ox.gdf_from_place('Helsinki, Finland').geometry.unary_union\n",
    "city2 = ox.gdf_from_place('Espoo, Finland').geometry.unary_union\n",
    "city3 = ox.gdf_from_place('Vantaa, Finland').geometry.unary_union\n",
    "city4 = ox.gdf_from_place('Kauniainen, Finland').geometry.unary_union\n",
    "HEL_ESP_VAN_KAU=GeoSeries([city1,city2,city3,city4]).unary_union\n",
    "\n",
    "asemat=gpd.read_file('.\\Helsingin_seudun_pyörälaskennat\\Helsingin_seudun_pyörälaskennat.shp')\n",
    "\n",
    "HEL_ESP_VAN_KAU=gpd.GeoDataFrame(pd.DataFrame(data=[HEL_ESP_VAN_KAU],columns=['geometry']))\n",
    "asemat=asemat.loc[asemat.within(HEL_ESP_VAN_KAU.geometry[0])]\n",
    "asemat=ox.project_gdf(asemat)\n",
    "\n",
    "HEL_boundary=gpd.read_file('.\\Helsinki\\Helsinki.shp').boundary\n",
    "ESP_boundary=gpd.read_file('.\\Espoo\\Espoo.shp').boundary\n",
    "VAN_boundary=gpd.read_file('.\\Vantaa\\Vantaa.shp').boundary\n",
    "HEL_landuse=gpd.read_file('.\\Helsinki_landuse\\Helsinki_landuse.shp')\n",
    "ESP_landuse=gpd.read_file('.\\Espoo_landuse\\Espoo_landuse.shp')\n",
    "VAN_landuse=gpd.read_file('.\\Vantaa_landuse\\Vantaa_landuse.shp')\n",
    "\n",
    "G_simple=ox.load_graphml('HEL_ESP_VAN_KAU_bike_routes_simple.graphml',folder='.')\n",
    "\n",
    "fig,ax,ax2=plot_bikers(HEL_boundary,ESP_boundary,VAN_boundary,HEL_landuse,ESP_landuse,VAN_landuse,asemat,'huip_2018',G_simple,'Maximum bike counts 2018',0,9000,snapshots=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use imagemagick to make animated gif and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!magick convert -delay 2500 -loop 0 ./pictures/snapshot*.png ./pictures/method.gif\n",
    "\n",
    "from IPython.display import Image;\n",
    "Image(\"./pictures/method.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare main data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers_arkki=ALL_Bikers.loc[ALL_Bikers.arkkipaiva].copy()\n",
    "\n",
    "ALL_Bikers_arkki=ALL_Bikers_arkki.groupby('Time').mean().T.iloc[7:,:]\n",
    "ALL_Bikers_arkki['x']=0.0\n",
    "ALL_Bikers_arkki['y']=0.0\n",
    "ALL_Bikers_arkki['Nimi2']=''\n",
    "ALL_Bikers_arkki['Kunta']=''\n",
    "ALL_Bikers_arkki.iloc[0:20,27]='Helsinki'\n",
    "ALL_Bikers_arkki.loc[cIndex_Vantaa,'Kunta']='Vantaa'\n",
    "ALL_Bikers_arkki.loc[cIndex_Espoo,'Kunta']='Espoo'\n",
    "ALL_Bikers_arkki=ALL_Bikers_arkki.reset_index().set_index(['Kunta','index']).sort_values(['Kunta','index'])\n",
    "ALL_Bikers_arkki.loc[('Espoo',slice(None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#asemat.iloc[:,0:4].sort_values(['Kunta','Paikka']).to_excel('asematpos.xls')\n",
    "\n",
    "This export was used to create a handcrafted position file which is later treated here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare for join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers_arkki=ALL_Bikers_arkki.reset_index().set_index('Kunta')\n",
    "ALL_Bikers_arkki.loc['Helsinki','Nimi2']=HEL_pisteet['Unnamed: 0'].values\n",
    "ALL_Bikers_arkki.loc['Helsinki','x']=HEL_pisteet.x.values\n",
    "ALL_Bikers_arkki.loc['Helsinki','y']=HEL_pisteet.y.values\n",
    "ALL_Bikers_arkki.reset_index().set_index(['Kunta','index']).iloc[51:61,24:]\n",
    "ALL_Bikers_arkki['Nr']=np.arange(84)\n",
    "ALL_Bikers_arkki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load postion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Positions=pd.read_excel('Positions.xls')\n",
    "Positions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and generate geometries for geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "geom=[]\n",
    "x=[]\n",
    "y=[] \n",
    "ID=[]\n",
    "for n in range(len(Positions)):\n",
    "    if Positions.loc[n,'x']<100:\n",
    "        P2=Positions.loc[n,'x']\n",
    "        point=asemat.loc[asemat.Id==P2,'geometry'].values[0]\n",
    "        geom.append(point)\n",
    "        x.append(point.coords[0][0])\n",
    "        y.append(point.coords[0][0])\n",
    "        ID.append(P2)\n",
    "    else:\n",
    "        geom.append(np.nan)\n",
    "        x.append(np.nan)\n",
    "        y.append(np.nan)\n",
    "        ID.append(np.nan)\n",
    "\n",
    "Positions['geometry']=geom\n",
    "Positions['x']=x\n",
    "Positions['y']=y\n",
    "Positions['ID']=ID\n",
    "Positions=Positions.dropna()\n",
    "Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove nans and convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers_arkki_dna=ALL_Bikers_arkki.copy()\n",
    "\n",
    "ALL_Bikers_arkki_dna['ID']=ID\n",
    "ALL_Bikers_arkki_dna['x']=x\n",
    "ALL_Bikers_arkki_dna['y']=y\n",
    "ALL_Bikers_arkki_dna['geometry']=geom\n",
    "\n",
    "\n",
    "ALL_Bikers_arkki_dna=ALL_Bikers_arkki_dna.dropna()\n",
    "\n",
    "cols = ALL_Bikers_arkki_dna.columns\n",
    "cols=cols[1:25]\n",
    "ALL_Bikers_arkki_dna[cols] = ALL_Bikers_arkki_dna[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "ALL_Bikers_arkki_dna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers_arkki_dna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping of the main data, using average data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers_taulukko=ALL_Bikers_arkki_dna.groupby('ID').sum().drop(columns=['x','y','Nr'])\n",
    "ALL_Bikers_taulukko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop some columns and join then make a geodataframe for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_geom=Positions.copy().set_index('ID').drop(columns=['index','Nimi2','x','y','Nr'])\n",
    "ALL_Bikers_taulukko=ALL_Bikers_taulukko.join(id_geom)\n",
    "ALL_Bikers_taulukko=gpd.GeoDataFrame(ALL_Bikers_taulukko)\n",
    "ALL_Bikers_taulukko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare column index for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=ALL_Bikers_taulukko.columns\n",
    "columns=columns[0:24]\n",
    "n_col=len(columns)\n",
    "columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(24):    \n",
    "    fig,ax,ax2=plot_bikers(HEL_boundary,ESP_boundary,VAN_boundary,HEL_landuse,ESP_landuse,VAN_landuse,ALL_Bikers_taulukko,columns[i],G_simple,f'Weekdays, average counts at {columns[i]}',0,500)\n",
    "    plt.gcf().savefig(f'./pictures/AVG_traff{i:02}.png', bbox_inches='tight', dpi=400);\n",
    "    plt.clf();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use again imagemagick to make an animated gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!magick convert -delay 500 -loop 0 ./pictures/AVG_traff*.png ./pictures/AVG_traff.gif\n",
    "\n",
    "from IPython.display import Image;\n",
    "Image(\"./pictures/AVG_traff.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select data from 2018-2019 for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers_useful=ALL_Bikers.copy().loc['2018-07-01':,:]\n",
    "ALL_Bikers_useful=ALL_Bikers_useful.loc[ALL_Bikers_useful.nData>=30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers_useful.plot(y='nData',marker='o',linestyle='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Bikers_useful=ALL_Bikers_useful.loc[ALL_Bikers_useful.arkkipaiva].T.dropna().T\n",
    "ALL_Bikers_select=ALL_Bikers_useful.copy().loc[(ALL_Bikers_useful.Time=='07:00:00')|(ALL_Bikers_useful.Time=='07:00:00')]\n",
    "\n",
    "ALL_Bikers_select.iloc[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=ALL_Bikers_select.columns\n",
    "cols=cols[10:]\n",
    "\n",
    "for n in range(len(cols)):\n",
    "    ALL_Bikers_select.loc[:,cols[n]] = ALL_Bikers_select.loc[:,cols[n]].apply(pd.to_numeric)\n",
    "\n",
    "ALL_Bikers_select.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now group , calculate averages to remove nans and join Data with positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Data=ALL_Bikers_select.groupby(['month','Weekday']).mean().T\n",
    "Data_HEL=Data.iloc[0:17].sort_index()\n",
    "Data_ESP=Data.iloc[17:].sort_index()\n",
    "\n",
    "ESP=[0,None,6,20,23,25,32,36,None]\n",
    "HEL=[40,41,42,43,44,45,46,47,48,49,50,52,53,54,56,57,58]\n",
    "Data_HEL['Nr']=HEL\n",
    "Data_ESP['Nr']=ESP\n",
    "\n",
    "#Data_HEL.merge(Data_ESP)\n",
    "Data=pd.concat([Data_ESP,Data_HEL],axis=0).dropna()\n",
    "Data=Data.reset_index().set_index('Nr')\n",
    "Pos=Positions.set_index('Nr')\n",
    "\n",
    "index=Data.index\n",
    "geom=np.array(Pos.loc[index].geometry)\n",
    "Data['geometry']=geom\n",
    "Data=Data.set_index('index')\n",
    "Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the correlations between the counts look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_table=pd.DataFrame(Data.iloc[:,1:-1].values.astype('Float64').T).corr()\n",
    "\n",
    "\n",
    "#corr_table.columns=Mon_8_9_1.columns[9:]\n",
    "#corr_table.index=Mon_8_9_1.columns[9:]\n",
    "corr_table\n",
    "\n",
    "plt.pcolor(corr_table)\n",
    "corr_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the first n principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#print(ALL_arkki_8.iloc[:,9:])\n",
    "\n",
    "# Try first all components\n",
    "X=Data.iloc[:,1:-1].values.astype('Float64')\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "print('Singular values :\\n {}\\n'.format(pca.singular_values_))\n",
    "print('Explained variance /%  :\\n {}\\n'.format(pca.explained_variance_ratio_*100))\n",
    "print('Principal components :\\n {} \\n'.format( pca.components_))\n",
    "\n",
    "P=pca.components_[:,0:3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataplot=gpd.GeoDataFrame(geometry=Data.iloc[:,-1].values)\n",
    "Dataplot['P0']=P[:,0]\n",
    "Dataplot['P1']=P[:,1]\n",
    "Dataplot['P2']=P[:,2]\n",
    "Dataplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot them into a gif animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=Dataplot.columns\n",
    "columns=columns[1:4]\n",
    "n_col=len(columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):    \n",
    "    fig,ax,ax2=plot_bikers(HEL_boundary,ESP_boundary,VAN_boundary,HEL_landuse,ESP_landuse,VAN_landuse,Dataplot,columns[i],G_simple,f'Principal component Nr.  {i+1}',-0.5,0.5,barlabel=False)\n",
    "    plt.gcf().savefig(f'./pictures/PC{i+1:01}.png', bbox_inches='tight', dpi=400);\n",
    "    plt.clf();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!magick convert -delay 500 -loop 0 ./pictures/PC*.png ./pictures/PCA.gif\n",
    "\n",
    "from IPython.display import Image;\n",
    "Image(\"./pictures/PCA.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "It appears that visualising the data normally gives a better insight into the traffic of bikes, yet it is very difficutlt to find out from where to where. Also, correlating the count data does neither give any particular patterns in the covariane matrix, nor does the PCA result in any more meaningful patterns that could help to clarify the  direction of traffic.\n",
    "\n",
    "Another possibility is that the data quality is not good enough to make such an analysis possible.\n",
    "\n",
    "Thus, in this case at least, visualising the data and inspection by eye gives more insight than a pure mathematical approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
